#!/bin/bash --login
########## Define Resources Needed with SBATCH Lines ##########

#SBATCH --time=6:00:00             # limit of wall clock time - how long the job will run (same as -t)
#SBATCH --ntasks=1                 # number of tasks - how many tasks (nodes) that you require (same as -n)
#SBATCH --cpus-per-task=6          # number of CPUs (or cores) per task (same as -c)
#SBATCH --mem=1G                   # memory required per node - amount of memory (in bytes)
#SBATCH --job-name=sra_download_<target>-<region>-<layout>       # you can give your job a name for easier identification (same as -J)
#SBATCH --output=%x-%j.SLURMout
#SBATCH --partition=scavenger

########## Command Lines to Run ##########

module load SRA-Toolkit/2.9.6-1

FP=/hpc/group/bio556l-s23/jal138/phyllosphere_evolution/data/SRA_files

TARGET=<target>
REGION=<region>
LAYOUT=<layout>

if ! [ -d $FP/"$TARGET"_"$REGION"_"$LAYOUT" ]
then
  mkdir -p $FP/"$TARGET"_"$REGION"_"$LAYOUT"
fi

while IFS= read -r line
do
  # TARGET=$(echo $line | cut -f1 -d' ')
  # REGION=$(echo $line | cut -f2 -d' ')
  SRA_ACC=$line
  echo "$TARGET"_"$REGION"_"$LAYOUT"/"$SRA_ACC"
  cd $FP/"$TARGET"_"$REGION"_"$LAYOUT"
  fasterq-dump $SRA_ACC
done < ../data/metadata/srr_list_"$TARGET"_"$REGION"_"$LAYOUT".txt
